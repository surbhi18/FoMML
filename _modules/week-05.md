---
title: Foundation Models
---

Oct 17
: **Lecture**{: .label .label-purple } LLMs/Transformers - History, Basics

Oct 19
: **Dicussion**{: .label .label-blue } LLMs/Transformers - Reasoning
: - Paper A: [Transformers Learn Shortcuts to Automata](https://arxiv.org/abs/2210.10749)
  - (_recommended_) [Blog](https://clarabing.github.io/shortcut_automata/) about Transformers Learn Shortcuts to Automata
  - (_optional_) [Self-Attention Networks Can Process Bounded Hierarchical Languages](https://aclanthology.org/2021.acl-long.292.pdf)
: - Paper B: [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)

Oct 24
: **Dicussion**{: .label .label-blue } LLMs/Transformers - In-context Learning
: - Paper A: [What Can Transformers Learn In-Context? A Case Study of Simple Function Classes](https://arxiv.org/pdf/2111.02080.pdf)
: - Paper B: [An Explanation of In-context Learning as Implicit Bayesian Inference](https://arxiv.org/pdf/2111.02080.pdf)
  - (_optional_) [Transformers learn in-context by gradient descent](https://arxiv.org/abs/2212.07677)

Oct 26
: **Lecture**{: .label .label-purple } Diffusion Models - History, Basics

Oct 31
: **Dicussion**{: .label .label-blue } Diffusion Models - Part 2
